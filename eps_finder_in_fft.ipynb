{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import tqdm\n",
    "import time\n",
    "import os\n",
    "import wandb\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from external_utils import format_time\n",
    "from utils.data_preprocessing import preprocess_dataset_get_data_loader, generate_merged_dataset_from_two_loader, generate_dataset_from_loader,preprocess_mnist_fmnist,get_data_loader\n",
    "from structure.dlgn_conv_config_structure import DatasetConfig\n",
    "from collections import OrderedDict\n",
    "\n",
    "from visualization import recreate_image, save_image,  PerClassDataset\n",
    "from utils.data_preprocessing import true_segregation\n",
    "from structure.generic_structure import CustomSimpleDataset\n",
    "from adversarial_attacks_tester import generate_adv_examples\n",
    "\n",
    "from cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.torch.attacks.projected_gradient_descent import (\n",
    "    projected_gradient_descent,\n",
    ")\n",
    "\n",
    "from keras.datasets import mnist, fashion_mnist\n",
    "\n",
    "from conv4_models import get_model_instance, get_model_instance_from_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_from_path(dataset, model_arch_type, model_path, mask_percentage=40):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    temp_model = torch.load(model_path, map_location=device)\n",
    "    custom_model = get_model_instance_from_dataset(\n",
    "        dataset, model_arch_type)\n",
    "    if(\"masked\" in model_arch_type):\n",
    "        custom_model = get_model_instance_from_dataset(\n",
    "            dataset, model_arch_type, mask_percentage=mask_percentage)\n",
    "    if(isinstance(temp_model, dict)):\n",
    "        if(\"module.\" in [*temp_model['state_dict'].keys()][0]):\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in temp_model['state_dict'].items():\n",
    "                name = k[7:]  # remove 'module.' of dataparallel\n",
    "                new_state_dict[name] = v\n",
    "            custom_model.load_state_dict(new_state_dict)\n",
    "        else:\n",
    "            custom_model.load_state_dict(temp_model['state_dict'])\n",
    "    else:\n",
    "        custom_model.load_state_dict(temp_model.state_dict())\n",
    "\n",
    "    return custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eps_fft(dataloader1,dataloader2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    eps = float(\"-inf\")\n",
    "    iter_dataloader2 = enumerate(dataloader2)\n",
    "    loader = tqdm.tqdm(dataloader1, desc='Generating perturbation FFT')\n",
    "    for ind, data in enumerate(loader, 0):\n",
    "        inputs, _ = data\n",
    "        inputs = inputs.to(\n",
    "            device).type(torch.float64)\n",
    "        _,(inputs2,_) = next(iter_dataloader2)\n",
    "        inputs2 = inputs2.to(\n",
    "            device).type(torch.float64)\n",
    "        assert inputs2.size()==inputs.size(), \"Not same sizes:{} vs {} at ind:{}\".format(inputs.size(),inputs2.size(),ind)\n",
    "        diff = torch.abs(torch.fft.fft2(inputs2) - torch.fft.fft2(inputs))\n",
    "        eps = max(eps,torch.max(diff).item())\n",
    "    \n",
    "    return eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing over mnist\n",
      "Loading adversarial examples from path: root/model/save/mnist/adversarial_training/MT_dlgn__conv4_dlgn_pad_k_1_st1_bn_wo_bias___ET_ADV_TRAINING/ST_2022/fast_adv_attack_type_PGD/adv_type_PGD/EPS_0.06/batch_size_128/eps_stp_size_0.06/adv_steps_80//RAW_ADV_SAVES/adv_type_PGD/EPS_0.06/eps_stp_size_0.06/adv_steps_161/on_train_False//adv_dataset.npy\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # fashion_mnist , mnist, cifar10\n",
    "    dataset = 'mnist'\n",
    "    # conv4_dlgn , plain_pure_conv4_dnn , conv4_dlgn_n16_small , plain_pure_conv4_dnn_n16_small , conv4_deep_gated_net , conv4_deep_gated_net_n16_small\n",
    "    # fc_dnn , fc_dlgn , fc_dgn , dlgn__conv4_dlgn_pad_k_1_st1_bn_wo_bias__\n",
    "    model_arch_type = 'dlgn__conv4_dlgn_pad_k_1_st1_bn_wo_bias__'\n",
    "    batch_size = 64\n",
    "\n",
    "    is_analysis_on_train = False\n",
    "\n",
    "    torch_seed = 2022\n",
    "\n",
    "    # None means that train on all classes\n",
    "    list_of_classes_to_train_on = None\n",
    "    # list_of_classes_to_train_on = [4, 9]\n",
    "\n",
    "    # Percentage of information retention during PCA (values between 0-1)\n",
    "    pca_exp_percent = None\n",
    "    # pca_exp_percent = 0.85\n",
    "\n",
    "    is_analyse_adv = True\n",
    "\n",
    "    wandb_config_additional_dict = None\n",
    "    # wandb_config_additional_dict = {\"type_of_APR\": \"APRS\"}\n",
    "\n",
    "    direct_model_path = \"root/model/save/mnist/adversarial_training/MT_dlgn__conv4_dlgn_pad_k_1_st1_bn_wo_bias___ET_ADV_TRAINING/ST_2022/fast_adv_attack_type_PGD/adv_type_PGD/EPS_0.06/batch_size_128/eps_stp_size_0.06/adv_steps_80/adv_model_dir.pt\"\n",
    "\n",
    "    custom_dataset_path = None\n",
    "    # custom_dataset_path = \"data/custom_datasets/freq_band_dataset/mnist__MB_HB.npy\"\n",
    "\n",
    "    if(dataset == \"cifar10\"):\n",
    "        inp_channel = 3\n",
    "        classes = ('plane', 'car', 'bird', 'cat',\n",
    "                    'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        num_classes = len(classes)\n",
    "\n",
    "        cifar10_config = DatasetConfig(\n",
    "            'cifar10', is_normalize_data=False, valid_split_size=0.1, batch_size=batch_size, \n",
    "            list_of_classes=list_of_classes_to_train_on,custom_dataset_path=custom_dataset_path)\n",
    "\n",
    "        trainloader, _, testloader = preprocess_dataset_get_data_loader(\n",
    "            cifar10_config, model_arch_type, verbose=1, dataset_folder=\"./Datasets/\", is_split_validation=False)\n",
    "\n",
    "    elif(dataset == \"mnist\"):\n",
    "        inp_channel = 1\n",
    "        classes = [str(i) for i in range(0, 10)]\n",
    "        num_classes = len(classes)\n",
    "\n",
    "        ds_config = DatasetConfig(\n",
    "            'mnist', is_normalize_data=True, valid_split_size=0.1, batch_size=batch_size, \n",
    "            list_of_classes=list_of_classes_to_train_on,custom_dataset_path=custom_dataset_path)\n",
    "\n",
    "        trainloader, _, testloader = preprocess_dataset_get_data_loader(\n",
    "            ds_config, model_arch_type, verbose=1, dataset_folder=\"./Datasets/\", is_split_validation=False)\n",
    "\n",
    "    elif(dataset == \"fashion_mnist\"):\n",
    "        inp_channel = 1\n",
    "        classes = ('T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "                    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-boot')\n",
    "        num_classes = len(classes)\n",
    "\n",
    "        ds_config = DatasetConfig(\n",
    "            'fashion_mnist', is_normalize_data=True, valid_split_size=0.1, batch_size=batch_size, \n",
    "            list_of_classes=list_of_classes_to_train_on,custom_dataset_path=custom_dataset_path)\n",
    "\n",
    "        trainloader, _, testloader = preprocess_dataset_get_data_loader(\n",
    "            ds_config, model_arch_type, verbose=1, dataset_folder=\"./Datasets/\", is_split_validation=False)\n",
    "\n",
    "    if(custom_dataset_path is not None):\n",
    "        dataset = custom_dataset_path[custom_dataset_path.rfind(\"/\")+1:custom_dataset_path.rfind(\".npy\")]\n",
    "\n",
    "    print(\"Testing over \"+dataset)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    num_classes_trained_on = num_classes\n",
    "    dataset_str = dataset\n",
    "\n",
    "    list_of_classes_to_train_on_str = \"\"\n",
    "    if(list_of_classes_to_train_on is not None):\n",
    "        for each_class_to_train_on in list_of_classes_to_train_on:\n",
    "            list_of_classes_to_train_on_str += \\\n",
    "                str(each_class_to_train_on)+\"_\"\n",
    "        dataset_str += \"_\"+str(list_of_classes_to_train_on_str)\n",
    "        list_of_classes_to_train_on_str = \"TR_ON_\" + \\\n",
    "            list_of_classes_to_train_on_str[0:-1]\n",
    "        num_classes_trained_on = len(list_of_classes_to_train_on)\n",
    "        temp_classes = []\n",
    "        for ea_c in list_of_classes_to_train_on:\n",
    "            temp_classes.append(classes[ea_c])\n",
    "        classes = temp_classes\n",
    "\n",
    "    model_arch_type_str = model_arch_type\n",
    "    if(\"masked\" in model_arch_type):\n",
    "        mask_percentage = 90\n",
    "        model_arch_type_str = model_arch_type_str + \\\n",
    "            \"_PRC_\"+str(mask_percentage)\n",
    "        net = get_model_instance(\n",
    "            model_arch_type, inp_channel, mask_percentage=mask_percentage, seed=torch_seed, num_classes=num_classes_trained_on)\n",
    "    elif(\"fc\" in model_arch_type):\n",
    "        fc_width = 128\n",
    "        fc_depth = 4\n",
    "        nodes_in_each_layer_list = [fc_width] * fc_depth\n",
    "        model_arch_type_str = model_arch_type_str + \\\n",
    "            \"_W_\"+str(fc_width)+\"_D_\"+str(fc_depth)\n",
    "        net = get_model_instance_from_dataset(dataset,\n",
    "                                                model_arch_type, seed=torch_seed, num_classes=num_classes_trained_on, nodes_in_each_layer_list=nodes_in_each_layer_list)\n",
    "    else:\n",
    "        net = get_model_instance(model_arch_type, inp_channel,\n",
    "                                    seed=torch_seed, num_classes=num_classes_trained_on)\n",
    "\n",
    "    if(pca_exp_percent is not None):\n",
    "        dataset_for_pca = generate_dataset_from_loader(trainloader)\n",
    "        if(isinstance(dataset_for_pca.list_of_x[0], torch.Tensor)):\n",
    "            dataset_for_pca = torch.stack(\n",
    "                dataset_for_pca.list_of_x), torch.stack(dataset_for_pca.list_of_y)\n",
    "        else:\n",
    "            dataset_for_pca = np.array(dataset_for_pca.list_of_x), np.array(\n",
    "                dataset_for_pca.list_of_y)\n",
    "        number_of_components_for_pca = net.initialize_PCA_transformation(\n",
    "            dataset_for_pca[0], pca_exp_percent)\n",
    "        model_arch_type_str = model_arch_type_str + \\\n",
    "            \"_PCA_K\"+str(number_of_components_for_pca) + \\\n",
    "            \"_P_\"+str(pca_exp_percent)\n",
    "\n",
    "    if('CLEAN' in direct_model_path or 'APR_TRAINING' in direct_model_path or 'adv_model_dir_epoch' in direct_model_path):\n",
    "        data_save_prefix = direct_model_path[0:direct_model_path.rfind(\n",
    "            \".pt\")]\n",
    "    else:\n",
    "        data_save_prefix = direct_model_path[0:direct_model_path.rfind(\n",
    "            \"/\")+1]\n",
    "\n",
    "    isExist = os.path.exists(direct_model_path)\n",
    "    assert isExist == True, 'Model path does not have saved model'\n",
    "\n",
    "    net = get_model_from_path(\n",
    "        dataset, model_arch_type, direct_model_path)\n",
    "\n",
    "    net = net.to(device)\n",
    "    device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    if device_str == 'cuda':\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    if(is_analysis_on_train == True):\n",
    "        eval_loader = trainloader\n",
    "    else:\n",
    "        eval_loader = testloader\n",
    "    \n",
    "    number_of_adversarial_optimization_steps = 161\n",
    "    adv_attack_type = \"PGD\"\n",
    "    adv_target = None\n",
    "    eps_step_size = 0.06\n",
    "    eps = 0.06\n",
    "    is_adv_attack_on_train = is_analysis_on_train\n",
    "\n",
    "    final_adv_postfix_for_save = \"/RAW_ADV_SAVES/adv_type_{}/EPS_{}/eps_stp_size_{}/adv_steps_{}/on_train_{}/\".format(\n",
    "            adv_attack_type, eps, eps_step_size, number_of_adversarial_optimization_steps, is_adv_attack_on_train)\n",
    "    adv_save_path = data_save_prefix + \\\n",
    "        final_adv_postfix_for_save+\"/adv_dataset.npy\"\n",
    "    is_current_adv_aug_available = os.path.exists(\n",
    "        adv_save_path)\n",
    "    if(is_current_adv_aug_available):\n",
    "        with open(adv_save_path, 'rb') as file:\n",
    "            npzfile = np.load(adv_save_path)\n",
    "            list_of_adv_images = npzfile['x']\n",
    "            list_of_labels = npzfile['y']\n",
    "            adv_dataset = CustomSimpleDataset(\n",
    "                list_of_adv_images, list_of_labels)\n",
    "            print(\"Loading adversarial examples from path:\",\n",
    "                    adv_save_path)\n",
    "    else:\n",
    "        print(\"adv_save_path:\", adv_save_path)\n",
    "        adv_dataset = generate_adv_examples(\n",
    "            eval_loader, net, eps, adv_attack_type, number_of_adversarial_optimization_steps, eps_step_size, adv_target, is_save_adv=True, save_path=adv_save_path)\n",
    "    to_be_analysed_adversarial_dataloader = torch.utils.data.DataLoader(\n",
    "                        adv_dataset, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38.339999383315444 for PGD-AT model MNIST with attack EPS=0.06\\\\\n",
    "\n",
    "8.9 for PGD-AT model MNIST with attack EPS=0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating perturbation FFT: 100%|██████████| 157/157 [00:00<00:00, 201.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.339999383315444"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_eps_fft(eval_loader,to_be_analysed_adversarial_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-work-DAG-DNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
